{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2666d59e-fc52-4d9c-bfcf-cdccdeffccb1",
      "metadata": {
        "id": "2666d59e-fc52-4d9c-bfcf-cdccdeffccb1"
      },
      "source": [
        "# bistro (bayesian inference simplification for regression of treatment on outcome)\n",
        "\n",
        "### Version 1.0 (Python versions > 3.8)\n",
        "D. M. Burt\n",
        "\n",
        "\n",
        "### TODO\n",
        "1. Put ```plot_effects``` into class body.  \n",
        "2. Genericize ```plot_effects```:  \n",
        "    a. add a model type to specify difference-in-difference  \n",
        "    b. pass TREAT and POST as variables (rather than leaving them hardcoded as TREAT and POST)  \n",
        "3. Split data passed to fit into ```data_treat``` and ```data_control```.\n",
        "    a. Implement getters and setters for ```self.data_treat``` and ```self.data_control```.\n",
        "    b. ```self.data_control``` will be set/reset by matching function.\n",
        "4. Add propensity score estimation and matching  \n",
        "    a. nearest neighbor, caliper  \n",
        "5."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymc==4.4 # (at the moment, v5 is not working)\n",
        "# remove aesara (pymc started using pytensor, and recently there are ambiguity warnings coming from having both installed)\n",
        "!pip install bambi patsy seaborn graphviz watermark"
      ],
      "metadata": {
        "id": "vvdESM_i8PHh",
        "outputId": "eee06eeb-b762-42b3-c4d1-6322a835e7b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "vvdESM_i8PHh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymc==4.4\n",
            "  Using cached pymc-4.4.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: aeppl==0.0.38 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (0.0.38)\n",
            "Requirement already satisfied: aesara==2.8.7 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (2.8.7)\n",
            "Requirement already satisfied: arviz>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (0.21.0)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (3.1.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pymc==4.4) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from aesara==2.8.7->pymc==4.4) (3.18.0)\n",
            "Requirement already satisfied: etuples in /usr/local/lib/python3.11/dist-packages (from aesara==2.8.7->pymc==4.4) (0.3.9)\n",
            "Requirement already satisfied: logical-unification in /usr/local/lib/python3.11/dist-packages (from aesara==2.8.7->pymc==4.4) (0.4.6)\n",
            "Requirement already satisfied: miniKanren in /usr/local/lib/python3.11/dist-packages (from aesara==2.8.7->pymc==4.4) (1.0.3)\n",
            "Requirement already satisfied: cons in /usr/local/lib/python3.11/dist-packages (from aesara==2.8.7->pymc==4.4) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=48.0.0 in /usr/local/lib/python3.11/dist-packages (from aesara==2.8.7->pymc==4.4) (75.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc==4.4) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc==4.4) (24.2)\n",
            "Requirement already satisfied: xarray>=2022.6.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc==4.4) (2025.1.2)\n",
            "Requirement already satisfied: h5netcdf>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc==4.4) (1.6.1)\n",
            "Requirement already satisfied: xarray-einstats>=0.3 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.13.0->pymc==4.4) (0.8.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->pymc==4.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->pymc==4.4) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->pymc==4.4) (2025.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf>=1.0.2->arviz>=0.13.0->pymc==4.4) (3.13.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc==4.4) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc==4.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc==4.4) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc==4.4) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc==4.4) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->arviz>=0.13.0->pymc==4.4) (3.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->pymc==4.4) (1.17.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from logical-unification->aesara==2.8.7->pymc==4.4) (0.12.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from logical-unification->aesara==2.8.7->pymc==4.4) (1.0.0)\n",
            "Using cached pymc-4.4.0-py3-none-any.whl (590 kB)\n",
            "Installing collected packages: pymc\n",
            "  Attempting uninstall: pymc\n",
            "    Found existing installation: pymc 5.21.1\n",
            "    Uninstalling pymc-5.21.1:\n",
            "      Successfully uninstalled pymc-5.21.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bambi 0.15.0 requires pymc>=5.18.0, but you have pymc 4.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pymc-4.4.0\n",
            "Requirement already satisfied: bambi in /usr/local/lib/python3.11/dist-packages (0.15.0)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.20.3)\n",
            "Requirement already satisfied: watermark in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: arviz>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from bambi) (0.21.0)\n",
            "Requirement already satisfied: formulae>=0.5.3 in /usr/local/lib/python3.11/dist-packages (from bambi) (0.5.4)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bambi) (2.2.2)\n",
            "Collecting pymc>=5.18.0 (from bambi)\n",
            "  Using cached pymc-5.21.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.4 in /usr/local/lib/python3.11/dist-packages (from patsy) (2.0.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.11/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.11/dist-packages (from watermark) (8.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from watermark) (75.1.0)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.12.0->bambi) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from arviz>=0.12.0->bambi) (24.2)\n",
            "Requirement already satisfied: xarray>=2022.6.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.12.0->bambi) (2025.1.2)\n",
            "Requirement already satisfied: h5netcdf>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.12.0->bambi) (1.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.12.0->bambi) (4.12.2)\n",
            "Requirement already satisfied: xarray-einstats>=0.3 in /usr/local/lib/python3.11/dist-packages (from arviz>=0.12.0->bambi) (0.8.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=1.4->watermark) (3.21.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->bambi) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->bambi) (2025.1)\n",
            "Requirement already satisfied: cachetools>=4.2.1 in /usr/local/lib/python3.11/dist-packages (from pymc>=5.18.0->bambi) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from pymc>=5.18.0->bambi) (3.1.1)\n",
            "Requirement already satisfied: pytensor<2.29,>=2.28.2 in /usr/local/lib/python3.11/dist-packages (from pymc>=5.18.0->bambi) (2.28.3)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from pymc>=5.18.0->bambi) (13.9.4)\n",
            "Requirement already satisfied: threadpoolctl<4.0.0,>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from pymc>=5.18.0->bambi) (3.6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from h5netcdf>=1.0.2->arviz>=0.12.0->bambi) (3.13.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Requirement already satisfied: filelock>=3.15 in /usr/local/lib/python3.11/dist-packages (from pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (3.18.0)\n",
            "Requirement already satisfied: etuples in /usr/local/lib/python3.11/dist-packages (from pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (0.3.9)\n",
            "Requirement already satisfied: logical-unification in /usr/local/lib/python3.11/dist-packages (from pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (0.4.6)\n",
            "Requirement already satisfied: miniKanren in /usr/local/lib/python3.11/dist-packages (from pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (1.0.3)\n",
            "Requirement already satisfied: cons in /usr/local/lib/python3.11/dist-packages (from pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (0.4.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->pymc>=5.18.0->bambi) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->pymc>=5.18.0->bambi) (0.1.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from logical-unification->pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (0.12.1)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from logical-unification->pytensor<2.29,>=2.28.2->pymc>=5.18.0->bambi) (1.0.0)\n",
            "Using cached pymc-5.21.1-py3-none-any.whl (517 kB)\n",
            "Installing collected packages: pymc\n",
            "  Attempting uninstall: pymc\n",
            "    Found existing installation: pymc 4.4.0\n",
            "    Uninstalling pymc-4.4.0:\n",
            "      Successfully uninstalled pymc-4.4.0\n",
            "Successfully installed pymc-5.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e432fd34-611b-4665-b2c0-c98676832574",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-25T15:09:23.485809Z",
          "start_time": "2023-04-25T15:09:20.393700Z"
        },
        "id": "e432fd34-611b-4665-b2c0-c98676832574",
        "outputId": "b95e1b26-40c3-4bf6-da41-5dced6279b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-22 23:24:52--  https://github.com/dmburt/BayesianInference/tree/6b78fddd223e978eca51a5c2dae5bb7875b43b1e/resources/fonts/Roboto/Roboto-VariableFont.ttf\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/dmburt/BayesianInference/blob/6b78fddd223e978eca51a5c2dae5bb7875b43b1e/resources/fonts/Roboto/Roboto-VariableFont.ttf [following]\n",
            "--2025-03-22 23:24:52--  https://github.com/dmburt/BayesianInference/blob/6b78fddd223e978eca51a5c2dae5bb7875b43b1e/resources/fonts/Roboto/Roboto-VariableFont.ttf\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘Roboto-VariableFont.ttf’\n",
            "\n",
            "Roboto-VariableFont     [ <=>                ] 207.33K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-03-22 23:24:53 (3.25 MB/s) - ‘Roboto-VariableFont.ttf’ saved [212306]\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Can not load face (unknown file format; error code 0x2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-341fb67b52e8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://github.com/dmburt/BayesianInference/tree/6b78fddd223e978eca51a5c2dae5bb7875b43b1e/resources/fonts/Roboto/Roboto-VariableFont.ttf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfontManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Roboto-VariableFont.ttf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'font'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Roboto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36maddfont\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m   1134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafmlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m             \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mft2font\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFT2Font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m             \u001b[0mprop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mttfFontProperty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mttflist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Can not load face (unknown file format; error code 0x2)"
          ]
        }
      ],
      "source": [
        "# activate a python 3.11 virtual environment: source python3.11/bin/activate\n",
        "# pip install pymc==4.4 (at the moment, v5 is not working)\n",
        "# remove aesara (pymc started using pytensor, and recently there are ambiguity warnings coming from having both installed)\n",
        "# pip install bambi patsy seaborn graphviz\n",
        "\n",
        "# data libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import patsy as pt\n",
        "import xarray as xr\n",
        "\n",
        "# stats libraries\n",
        "#import pymc3 as pm\n",
        "import pymc as pm\n",
        "import bambi as bmb\n",
        "import arviz as az\n",
        "\n",
        "# control group matching libraries\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# viz libraries\n",
        "# Note: graphviz will require additional binaries to be installed\n",
        "import graphviz\n",
        "import seaborn as sns\n",
        "from tabulate import tabulate\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# fonts for Google Colab setup\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "\n",
        "!wget https://github.com/dmburt/BayesianInference/tree/6b78fddd223e978eca51a5c2dae5bb7875b43b1e/resources/fonts/Roboto/Roboto-VariableFont.ttf\n",
        "fm.fontManager.addfont('Roboto-VariableFont.ttf')\n",
        "matplotlib.rc('font', family='Roboto')\n",
        "\n",
        "from matplotlib import rc\n",
        "\n",
        "\n",
        "# Linux font setup\n",
        "rc('font',**{'family':'Roboto',\n",
        "             'sans-serif':['Helvetica', 'Roboto-Regular', 'Roboto', 'roboto', 'roboto-regular'],\n",
        "             'size':10\n",
        "            }\n",
        "  )\n",
        "\n",
        "\n",
        "'''\n",
        "# Windows font setup\n",
        "rc('font',**{'family':'sans-serif',\n",
        "             'sans-serif':['Aptos', 'Arial'],\n",
        "             'size':10\n",
        "            }\n",
        "  )\n",
        "'''\n",
        "\n",
        "import watermark\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ff6af2-d518-4709-8fcd-35992a2c0809",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:17:55.979619Z",
          "start_time": "2023-04-27T19:17:55.888914Z"
        },
        "id": "15ff6af2-d518-4709-8fcd-35992a2c0809"
      },
      "outputs": [],
      "source": [
        "__version__ = '1.0.20221230'\n",
        "\n",
        "class BModel:\n",
        "\n",
        "    def _convert_dataset(self, dataset, dataset_name):\n",
        "        '''\n",
        "        _convert_dataset\n",
        "        Test if dataset is of type xarray Dataset.  If the dataset is pandas, convert to xarray Dataset.\n",
        "        If the dataset is not of a supported type, throw error.\n",
        "        '''\n",
        "        accepted_dataset_types = {'pandas DataFrame': pd.core.frame.DataFrame,\n",
        "                                  'xarray Dataset': xr.core.dataset.Dataset\n",
        "                                 }\n",
        "\n",
        "        # Pass xarray Dataset\n",
        "        if isinstance(dataset, xr.core.dataset.Dataset):\n",
        "            return dataset\n",
        "\n",
        "        # Convert pandas\n",
        "        if isinstance(dataset, pd.core.frame.DataFrame):\n",
        "            dataset_temp = dataset.copy(deep=True)\n",
        "            idx = pd.Index.rename(dataset_temp.index, name='observation')\n",
        "            dataset_temp.index = idx\n",
        "            return xr.Dataset.from_dataframe(dataset_temp)\n",
        "\n",
        "        # Fall-through case: throw error\n",
        "        raise Exception(f'The datasets passed must be of one of the following types: {accepted_dataset_types.keys()}.\\n \\\n",
        "                          The supplied dataset {dataset_name} is of type {type(dataset)}.')\n",
        "\n",
        "\n",
        "    def __init__(self, data_treat=None, data_control=None, treat_var=None):\n",
        "        '''\n",
        "        __init__\n",
        "        -------------\n",
        "        data_treat:   required.  Must be of type pandas DataFrame or xarray.\n",
        "        data_control: required.  Must be of type pandas DataFrame or xarray.\n",
        "        treat_var:    required.  If this variable does not exist in data_treat and/or data_control, it will\n",
        "                                 be added to the combined dataset returned by this method.\n",
        "\n",
        "        TODO: CURRENTLY DESIGNED FOR PANDAS.  NEED TO REFACTOR TO SUPPORT XARRAY AND NUMPY\n",
        "\n",
        "        '''\n",
        "\n",
        "        if treat_var is None:\n",
        "            raise Exception(f'The treat_var parameter must be specified.')\n",
        "\n",
        "        self.data_treat   = self._convert_dataset(data_treat, 'data_treat')\n",
        "        self.data_treat.attrs['bistro_version'] = __version__\n",
        "        self.data_treat.attrs['Treat group variable'] = treat_var\n",
        "        self.data_control = self._convert_dataset(data_control, 'data_control')\n",
        "        self.data_control.attrs['bistro_version'] = __version__\n",
        "        self.data_control.attrs['Treat group variable'] = treat_var\n",
        "\n",
        "\n",
        "        # Check to see if datasets have the same columns (not counting the treat indicator variable in either)\n",
        "        data_treat_vars   = sorted(list(self.data_treat.keys()))\n",
        "        data_treat_vars.remove(treat_var)\n",
        "\n",
        "        data_control_vars   = sorted(list(self.data_control.keys()))\n",
        "        data_control_vars.remove(treat_var)\n",
        "\n",
        "        if np.sum(data_treat_vars != data_control_vars) > 0:\n",
        "            raise Exception(f'data_treat and data_control have different variables (or at least differently-named).')\n",
        "\n",
        "        ## HERE!  Need to merge treat and control Datasets\n",
        "        # Start combined dataset for internal instance storage\n",
        "        self.data_combined = data_treat.copy(deep=True)  # do not want to merely create reference to original\n",
        "        temp_data_control  = data_control.copy(deep=True)\n",
        "\n",
        "        if treat_var not in self.data_combined.columns:\n",
        "            self.data_combined[treat_var] = int(1)\n",
        "\n",
        "        if treat_var not in data_control.columns:\n",
        "            temp_data_control[treat_var] = int(1)\n",
        "\n",
        "        self.data_combined = pd.concat([self.data_combined, temp_data_control], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _fit_did(self, reg_formula=None):\n",
        "        '''\n",
        "        _fit_did\n",
        "        Private function to fit difference-in-difference model.\n",
        "        Intended to be called from public fit() function with \"did\" type specification.\n",
        "\n",
        "        The reg_formula (patsy-style, see below) must refer to variables that exist in both data_control and\n",
        "        data_treat sets, with the exception of treat_var.  If the specified treat_var is not present in either\n",
        "        dataset (or both), then it will be added when data_treat and data_control are combined together.\n",
        "\n",
        "\n",
        "        ----------------\n",
        "        reg_formula:  required.  Formula in patsy style to describe DiD regression.\n",
        "                                 For a DiD regression, the formula is expected to have (at least) a binary TREAT\n",
        "                                 variable and a binary POST variable with an interaction term, such as:\n",
        "                                 \"outcome ~ treat + post + treat*post\".\n",
        "                                 More information on patsy formulas: https://patsy.readthedocs.io/en/latest/formulas.html\n",
        "\n",
        "\n",
        "        '''\n",
        "        self.reg_formula = reg_formula\n",
        "\n",
        "        # Patsy stuff, if needed.  May want to remove these in the future if not used.\n",
        "        self._did_y, self._did_x = pt.dmatrices(formula_like=reg_formula, data=self.data_combined)\n",
        "        self._did_y = np.asarray(self._did_y).flatten()\n",
        "\n",
        "        if isinstance(self.data_combined, xr.core.dataset.Dataset):\n",
        "            self.fitted_model = bmb.Model(reg_formula, self.data_combined.to_dataframe()).fit()\n",
        "        elif isinstance(self.data_combined, pd.core.frame.DataFrame):\n",
        "            self.fitted_model = bmb.Model(reg_formula, self.data_combined).fit()\n",
        "\n",
        "    def fit(self, model_type='did', reg_formula=None):\n",
        "        '''\n",
        "        fit\n",
        "        Public function to fit regression model.\n",
        "\n",
        "        ------------------\n",
        "        model_type:  required.  Currently only supports \"did\" (difference-in-difference)\n",
        "        reg_formula: required.  Formula in patsy style.  Specification depends on model type (more below).\n",
        "\n",
        "\n",
        "        Patsy formula specifications:\n",
        "\n",
        "        For a DiD regression, the formula is expected to have (at least) a binary TREAT\n",
        "        variable and a binary POST variable with an interaction term, such as:\n",
        "        \"outcome ~ treat + post + treat*post\".\n",
        "        More information on patsy formulas: https://patsy.readthedocs.io/en/latest/formulas.html\n",
        "\n",
        "\n",
        "        '''\n",
        "\n",
        "        valid_model_types = ['did']\n",
        "\n",
        "        if model_type is None:\n",
        "            raise Exception(f'Fit requires model _type to be specified (currently supported: {valid_model_types}).')\n",
        "        if model_type not in valid_model_types:\n",
        "            raise Exception(f'Fit requires model _type to be one of {valid_model_types}), but {model_type} was given.')\n",
        "\n",
        "        if model_type=='did':\n",
        "            self._fit_did(reg_formula=reg_formula)\n",
        "\n",
        "\n",
        "\n",
        "    def plot_trace(self):\n",
        "        '''\n",
        "        plot_trace\n",
        "        Convenience function for arviz plot_trace\n",
        "        '''\n",
        "        az.plot_trace(self.fitted_model)\n",
        "        plt.tight_layout()\n",
        "        sns.despine()\n",
        "        plt.show();\n",
        "\n",
        "\n",
        "\n",
        "    def _plot_hdi_density(self, data=None, interval=0.89, figsize=None):\n",
        "        '''\n",
        "        _plot_hdi_density\n",
        "        Private function to simplify a Seaborn kernel density estimate plot of data distributions\n",
        "        ----------------\n",
        "        data:      optional.  Defaults to posterior estimates of fitted_model\n",
        "        interval:  optional.  Defaults to 0.89 (i.e., 89% HDI).  Must be between 0.01 and 0.99.\n",
        "        '''\n",
        "\n",
        "        if data is None:\n",
        "            data = self.fitted_model['posterior'].to_dataframe()\n",
        "\n",
        "        list_params = data.columns\n",
        "        n_params = len(list_params)\n",
        "\n",
        "        n_rows = np.floor(np.sqrt(n_params)).astype(int)\n",
        "        n_cols = np.ceil(n_params/n_rows).astype(int)\n",
        "\n",
        "        if (interval < 0.01 or interval > 0.99):\n",
        "            raise Exception(f'interval supplied ({interval}) is invalid--this parameter must be between 0.01 and 0.99 (inclusive).')\n",
        "\n",
        "        if figsize is None:\n",
        "            figsize = (n_cols*3, n_rows*3)\n",
        "\n",
        "        caption_zero = 'x=0 shown in red if it exists in the HDI.'\n",
        "\n",
        "        fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=figsize)\n",
        "        fig.suptitle(f'Density of Parameter Estimates ({int(interval*100):d}% HDI)')\n",
        "        fig.text(0.5, 0.935, caption_zero, ha='center', size=8, color='firebrick')\n",
        "\n",
        "        # turn off axes by default (we will turn them back on during the plotting loop)\n",
        "#         for cur_ax in ax:\n",
        "#             cur_ax.set_axis_off()\n",
        "\n",
        "        plot_index = 0\n",
        "\n",
        "        for cur_row in range(n_rows):\n",
        "            for cur_col in range(n_cols):\n",
        "\n",
        "                ax[cur_row][cur_col].set_axis_off()\n",
        "\n",
        "                if plot_index < n_params:\n",
        "\n",
        "                    ax[cur_row][cur_col].set_axis_on()\n",
        "\n",
        "                    # data setup with interpolation--data for plot is sampled from original data to reduce compute overhead\n",
        "                    # and interpolation is added for KDE smoothing.\n",
        "                    #data_sample = np.random.choice(self.data.iloc[:,p], replace=False, size=min([len(self.data.iloc[:,p]), 1000]))\n",
        "                    data_sample = data.iloc[:,plot_index].sample(min([len(data.iloc[:,plot_index]), 1000]), replace=False)\n",
        "                    #data_sample.sort()\n",
        "\n",
        "\n",
        "                    # highest-density interval (HDI) calculation, using the quantile range specified by the ::interval parameter\n",
        "                    # Note: this is actually an equal-tailed interval (ETI), as opposed to a true HDI, for simplicity in calculation\n",
        "                    #       I'm assuming the parameter estimates will be reasonably symmetrical (not necessarily true for posterior),\n",
        "                    #       hence the reason I'm cheating a little here.\n",
        "                    hdi_lo = np.quantile(data_sample, ((1-interval)/2))\n",
        "                    hdi_hi = np.quantile(data_sample, (1-(1-interval)/2))\n",
        "                    hdi_median = np.quantile(data_sample, 0.5)\n",
        "                    hdi_range = hdi_hi - hdi_lo\n",
        "\n",
        "\n",
        "                    # plot\n",
        "                    g = sns.kdeplot(data_sample, clip=(hdi_lo, hdi_hi), color='#333', fill='#777', alpha=0.6, ax=ax[cur_row][cur_col])\n",
        "                    g.set_title(f'{list_params[plot_index]}', size=10)\n",
        "                    g.set_xlim(hdi_lo-0.2*hdi_range, hdi_hi+0.2*hdi_range)\n",
        "                    g.xaxis.set_tick_params(labelsize=8)\n",
        "                    g.xaxis.set_label_text(' ')\n",
        "                    g.yaxis.set_tick_params(labelsize=8)\n",
        "                    if cur_col != 0:\n",
        "                        g.yaxis.set_label_text(' ')\n",
        "\n",
        "                    # plot x=0, if it is within the HDI (ETI)\n",
        "                    if hdi_lo < 0 and hdi_hi > 0:\n",
        "                        g.axvline(0, color='firebrick', alpha=0.2, linestyle='--')\n",
        "                    g.axvline(hdi_median, color='#fff', linestyle=':')\n",
        "                    g.annotate(xy=[hdi_median + hdi_range*0.02, g.get_ylim()[1]*0.02], text=f'median:\\n{np.round(hdi_median,3)}', color='w', size=8)\n",
        "                    g.axvline(hdi_lo, color='#777', linestyle=':')\n",
        "                    g.annotate(xy=[hdi_lo + hdi_range*0.02, g.get_ylim()[1]*.9], text=f'{(1-interval)/2*100:.1f}%:\\n{np.round(hdi_lo,3)}', color='#222', size=8)\n",
        "                    g.axvline(hdi_hi, color='#777', linestyle=':')\n",
        "                    g.annotate(xy=[hdi_hi + hdi_range*0.02, g.get_ylim()[1]*.9], text=f'{(1-(1-interval)/2)*100:.1f}%:\\n{np.round(hdi_hi,3)}', color='#222',size=8)\n",
        "\n",
        "                plot_index += 1\n",
        "\n",
        "        plt.tight_layout()\n",
        "        sns.despine()\n",
        "        plt.show();\n",
        "\n",
        "\n",
        "    def label_line (self, line, label, x_pos, ax, label_fontsize, y_pad=None, color=None,\n",
        "                    angle_deg=None, split_point=0, above_line=True):\n",
        "        '''\n",
        "        label_line\n",
        "        -----------\n",
        "        line:\n",
        "        label:\n",
        "        x_pos:\n",
        "        ax:\n",
        "        y_pad:      optional.  Defaults with auto-scaling\n",
        "        color:      optional.  Defaults to line color\n",
        "        angle_deg:  DEV FN TO BE DEPRECATED AFTER ROTATION FEATURE VERIFIED\n",
        "        split_point:\n",
        "        above_line: Boolean value, defaulted to True, that specifies if label should appear above the line.\n",
        "                    A value of False will put the label below the line.\n",
        "        '''\n",
        "\n",
        "\n",
        "        line_xydata = line.get_xydata()\n",
        "        line_xydata = line_xydata[line_xydata[:,0]>=split_point]\n",
        "        y_lim = ax.get_ylim()\n",
        "        intercept = line_xydata[0][1]\n",
        "        rise = line_xydata[-1][1] - intercept\n",
        "        run = line_xydata[-1][0] - split_point\n",
        "        y_pos = intercept + x_pos*(rise*run)\n",
        "\n",
        "\n",
        "        if angle_deg is None:\n",
        "            angle_deg = np.degrees(np.arctan2(rise,run))\n",
        "\n",
        "\n",
        "        if y_pad is None:\n",
        "            y_pad = 0.02 * (y_lim[1]-y_lim[0])\n",
        "\n",
        "        if color is None:\n",
        "            color = line.get_color()\n",
        "\n",
        "\n",
        "        ax.text(x=x_pos,\n",
        "                y=y_pos + (1 if above_line else -1.5) * y_pad,\n",
        "                s=label,\n",
        "                size=label_fontsize,\n",
        "                rotation=(angle_deg),\n",
        "                rotation_mode='anchor',\n",
        "                transform_rotates_text=True,\n",
        "                color=color\n",
        "               )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_effects(self,\n",
        "                     model,\n",
        "                     line_type='single',\n",
        "                     show_intervals=True,\n",
        "                     split_point=0,\n",
        "                     n_lines=10,\n",
        "                     figsize=(9,3),\n",
        "                     hdi=0.89,\n",
        "                     plot_interval=True,\n",
        "                     show_did=False,\n",
        "                     title_fontsize=12,\n",
        "                     suptitle_fontsize=14,\n",
        "                     tick_fontsize=8,\n",
        "                     label_fontsize=10,\n",
        "                     control_color='#333333',\n",
        "                     treat_factual_color='#1295D8',\n",
        "                     treat_counterfactual_color='#005581',\n",
        "                     y_label='Y',\n",
        "                     y_pad = (0.02, 0.02, 0.02),\n",
        "                     labels_above_line = (True, True, True)\n",
        "                    ):\n",
        "        '''\n",
        "        plot_effects\n",
        "        -----------\n",
        "        Plot difference-in-difference results as regression lines\n",
        "\n",
        "\n",
        "        TODO: 1) Currently requires that ind. variables are named TREAT and POST.\n",
        "                 May require a function in the class to extract variables (and exclude outcome var).\n",
        "\n",
        "\n",
        "        model:\n",
        "        line_type:\n",
        "        show_intervals:\n",
        "        split_point:    optional.  Split factual and counterfactual lines along x at this point (between 0 and 1)\n",
        "        n_lines:        optional.  Used in multi mode, and specifies the number of sample lines to plot from posterior.\n",
        "                                    Defaults to 10.\n",
        "        figsize:        optional.  Tuple specifiying size of plot, in inches (width, height).\n",
        "        hdi:            optional.  Highest-density interval, used to plot credible interval in single mode.  Must be\n",
        "                                   greater than 0 and less than 1.\n",
        "        plot_interval   optional.  If True, plot the highest-density interval around the lines.  Only available in\n",
        "                                   single mode.  If specified in multi mode, this parameter will be ignored.\n",
        "        show_did        optional.  If True, plot the difference-in-difference line to show the meaningful effect.\n",
        "        title_fontsize\n",
        "        tick_fontsize\n",
        "        label_fontsize\n",
        "        control_color\n",
        "        treat_factual_color\n",
        "        treat_counterfactual_color\n",
        "        y_label\n",
        "        y_pad                      Tuple of floats that control padding to apply to y-position.\n",
        "                                   The positions in the tuple correspond to:\n",
        "                                   (treat_factual, treat_counterfactual, control)\n",
        "\n",
        "        labels_above_line          Tuple of booleans that control whether labels appear above (True) or below (False)\n",
        "                                   their respective lines.  The positions in the tuple correspond to:\n",
        "                                   (treat_factual, treat_counterfactual, control)\n",
        "        '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Validations\n",
        "        if (hdi <= 0) or (hdi >= 1):\n",
        "            raise Exception(f\"plot_effects() hdi parameter must be between 0 and 1 (exclusive), but {hdi} was specified.\")\n",
        "\n",
        "\n",
        "        # Establish dataset\n",
        "        temp_intercept = self.fitted_model['posterior']['Intercept'].to_numpy().ravel()\n",
        "        temp_treat = self.fitted_model['posterior']['TREAT'].to_numpy().ravel()\n",
        "        temp_post = self.fitted_model['posterior']['POST'].to_numpy().ravel()\n",
        "        temp_interact = self.fitted_model['posterior']['TREAT:POST'].to_numpy().ravel()\n",
        "\n",
        "\n",
        "        interval = (1-hdi)\n",
        "        interval_point_lo = interval/2\n",
        "        interval_point_hi = 1-interval/2\n",
        "\n",
        "\n",
        "        # Reduce dataset for plotting, based on line_type mode\n",
        "        if line_type == 'single':\n",
        "            plt_intercept = np.asarray([np.quantile(temp_intercept, 0.5)])\n",
        "            plt_treat = np.asarray([np.quantile(temp_treat, 0.5)])\n",
        "            plt_post = np.asarray([np.quantile(temp_post, 0.5)])\n",
        "            plt_interact = np.asarray([np.quantile(temp_interact, 0.5)])\n",
        "            n_lines = 1\n",
        "            line_alpha = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            hdi_lo_intercept = np.asarray([np.quantile(temp_intercept, interval_point_lo)])\n",
        "            hdi_hi_intercept = np.asarray([np.quantile(temp_intercept, interval_point_hi)])\n",
        "            hdi_lo_treat = np.asarray([np.quantile(temp_treat, interval_point_lo)])\n",
        "            hdi_hi_treat = np.asarray([np.quantile(temp_treat, interval_point_hi)])\n",
        "            hdi_lo_post = np.asarray([np.quantile(temp_post, interval_point_lo)])\n",
        "            hdi_hi_post = np.asarray([np.quantile(temp_post, interval_point_hi)])\n",
        "            hdi_lo_interact = np.asarray([np.quantile(temp_interact, interval_point_lo)])\n",
        "            hdi_hi_interact = np.asarray([np.quantile(temp_interact, interval_point_hi)])\n",
        "\n",
        "\n",
        "        elif line_type == 'multi':\n",
        "            plt_intercept = temp_intercept\n",
        "            plt_treat = temp_treat\n",
        "            plt_post = temp_post\n",
        "            plt_interact = temp_interact\n",
        "            line_alpha = 0.1\n",
        "            plot_interval = None\n",
        "        else:\n",
        "            raise Exception(f\"plot_effects() line_type parameter takes the values 'single' or 'multi'. {line_type} was specified.\")\n",
        "\n",
        "\n",
        "        #split_point=0 if diverge_midway==True else 0.5\n",
        "\n",
        "\n",
        "        fig, ax = plt.subplots(1,2, figsize=figsize)\n",
        "\n",
        "\n",
        "        ylim_padding = 0.1 # percent of slope/effect\n",
        "\n",
        "\n",
        "        # Establish y-axis limits, using all pertinent data for plotting\n",
        "        ylim_lo = np.min([0,\n",
        "                          np.min(plt_intercept) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_treat)) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_post)) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_treat + plt_post)) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_treat + plt_post + plt_interact)) * (1+ylim_padding)\n",
        "                         ]\n",
        "                        )\n",
        "\n",
        "\n",
        "        ylim_hi = np.max([np.min(plt_intercept) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_treat)) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_post)) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_treat + plt_post)) * (1+ylim_padding),\n",
        "                          (np.min(plt_intercept + plt_treat + plt_post + plt_interact)) * (1+ylim_padding)\n",
        "                         ]\n",
        "                        )\n",
        "\n",
        "\n",
        "        ax[0].set_ylim(np.min([0,ylim_lo]), ylim_hi)\n",
        "\n",
        "\n",
        "        # PLOTTING SECTION\n",
        "        for i in range(n_lines):\n",
        "\n",
        "\n",
        "            # Set up data\n",
        "            x = np.asarray([0, split_point, 1])\n",
        "            treat_y_counterfactual = np.asarray([plt_intercept[i] + plt_treat[i],\n",
        "                                                 plt_intercept[i] + plt_treat[i] + split_point*plt_post[i],\n",
        "                                                 plt_intercept[i] + plt_treat[i] + plt_post[i]\n",
        "                                                ])\n",
        "            treat_y_factual = np.asarray([plt_intercept[i] + plt_treat[i],\n",
        "                                          plt_intercept[i] + plt_treat[i] + split_point*plt_post[i] + 0*plt_interact[i],\n",
        "                                          plt_intercept[i] + plt_treat[i] + plt_post[i] + plt_interact[i]\n",
        "                                         ])\n",
        "            control_y = np.asarray([plt_intercept[i],\n",
        "                                    plt_intercept[i] + split_point*plt_post[i],\n",
        "                                    plt_intercept[i] + plt_post[i]\n",
        "                                   ])\n",
        "            did_y = np.asarray([plt_intercept[i] + plt_treat[i] + plt_post[i] + plt_interact[i],\n",
        "                                plt_intercept[i] + plt_treat[i] + plt_post[i]\n",
        "                               ])\n",
        "            did_direction = -1 if did_y[0] < did_y[1] else 1\n",
        "\n",
        "\n",
        "            # Plot lines\n",
        "            line_treat_counterfactual, = ax[0].plot(x,\n",
        "                                                 treat_y_counterfactual,\n",
        "                                                 color=treat_counterfactual_color,\n",
        "                                                 linestyle='--',\n",
        "                                                 alpha=line_alpha\n",
        "                                                )\n",
        "            line_treat_factual, = ax[0].plot(x,\n",
        "                                          treat_y_factual,\n",
        "                                          color=treat_factual_color,\n",
        "                                          alpha=line_alpha\n",
        "                                         )\n",
        "            line_control, = ax[0].plot(x,\n",
        "                                    control_y,\n",
        "                                    color=control_color,\n",
        "                                    alpha=line_alpha\n",
        "                                   )\n",
        "            if show_did:\n",
        "                if i==0:\n",
        "                    #ax.vlines(1.01, ymin=np.min(did_y), ymax=np.max(did_y), color='#FDB515')  #c4820e\n",
        "                    ax[0].arrow(1.02, did_y[1], dx=0,\n",
        "                             dy=did_direction*np.abs((did_y[0] - did_y[1])), length_includes_head=True,\n",
        "                             head_width=0.01, head_length=0.2,\n",
        "                             color='#FDB515')\n",
        "                    ax[0].annotate(f'DiD:\\n{did_direction*np.abs((did_y[0] - did_y[1])):.3f}',\n",
        "                                xy=[1.03, np.min(did_y)],\n",
        "                                color='#c4820e', size=label_fontsize\n",
        "                               )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Control axis size and tick labels.  If a non-zero split_point is specified, include \"intervention\"\n",
        "            ax[0].set_ylabel(y_label)\n",
        "            if split_point!=0:\n",
        "                ax[0].set_xticks([0, split_point, 1], labels=['PRE', 'Intervention', 'POST'], fontsize=tick_fontsize)\n",
        "                ax[0].axes.yaxis.set_tick_params(labelsize=tick_fontsize)\n",
        "                ax[0].axvline(x=split_point, linestyle=':', color='#333', alpha=0.2)\n",
        "            else:\n",
        "                ax[0].set_xticks([0,1], labels=['PRE','POST'], fontsize=tick_fontsize)\n",
        "                ax[0].axes.yaxis.set_tick_params(labelsize=tick_fontsize)\n",
        "\n",
        "\n",
        "            # Calculate and plot interval lines\n",
        "            if plot_interval is not None and plot_interval==True:\n",
        "\n",
        "\n",
        "                ### treat factual\n",
        "                treat_y_factual_interval_hi = np.asarray([hdi_hi_intercept + hdi_hi_treat,\n",
        "                                                          hdi_hi_intercept + hdi_hi_treat + split_point*hdi_hi_post + 0*hdi_hi_interact,\n",
        "                                                          hdi_hi_intercept + hdi_hi_treat + hdi_hi_post + hdi_hi_interact\n",
        "                                                         ])\n",
        "                treat_y_factual_interval_lo = np.asarray([hdi_lo_intercept + hdi_lo_treat,\n",
        "                                                          hdi_lo_intercept + hdi_lo_treat + split_point*hdi_lo_post + 0*hdi_lo_interact,\n",
        "                                                          hdi_lo_intercept + hdi_lo_treat + hdi_lo_post + hdi_lo_interact\n",
        "                                                         ])\n",
        "                line_treat_factual_interval_hi = ax[0].plot(x,\n",
        "                                                         treat_y_factual_interval_hi,\n",
        "                                                         color=treat_factual_color,\n",
        "                                                         alpha=0.05\n",
        "                                                        )\n",
        "                line_treat_factual_interval_lo = ax[0].plot(x,\n",
        "                                                         treat_y_factual_interval_lo,\n",
        "                                                         color=treat_factual_color,\n",
        "                                                         alpha=0.05\n",
        "                                                        )\n",
        "\n",
        "\n",
        "                ax[0].fill_between(x, np.ravel(treat_y_factual_interval_hi),\n",
        "                                np.ravel(treat_y_factual_interval_lo),\n",
        "                                color=treat_factual_color, alpha=0.05)\n",
        "\n",
        "\n",
        "                ### treat counterfactual\n",
        "                treat_y_counterfactual_interval_hi = np.asarray([hdi_hi_intercept + hdi_hi_treat,\n",
        "                                                                 hdi_hi_intercept + hdi_hi_treat + split_point*hdi_hi_post,\n",
        "                                                                 hdi_hi_intercept + hdi_hi_treat + hdi_hi_post\n",
        "                                                                ])\n",
        "                treat_y_counterfactual_interval_lo = np.asarray([hdi_lo_intercept + hdi_lo_treat,\n",
        "                                                                 hdi_lo_intercept + hdi_lo_treat + split_point*hdi_lo_post,\n",
        "                                                                 hdi_lo_intercept + hdi_lo_treat + hdi_lo_post\n",
        "                                                                ])\n",
        "                line_treat_counterfactual_interval_hi = ax[0].plot(x,\n",
        "                                                                treat_y_counterfactual_interval_hi,\n",
        "                                                                color=treat_counterfactual_color,\n",
        "                                                                alpha=0.05\n",
        "                                                               )\n",
        "                line_treat_counterfactual_interval_lo = ax[0].plot(x,\n",
        "                                                                treat_y_counterfactual_interval_lo,\n",
        "                                                                color=treat_counterfactual_color,\n",
        "                                                                alpha=0.05\n",
        "                                                               )\n",
        "\n",
        "\n",
        "                ax[0].fill_between(x, np.ravel(treat_y_counterfactual_interval_hi),\n",
        "                                np.ravel(treat_y_counterfactual_interval_lo),\n",
        "                                color=treat_counterfactual_color, alpha=0.05)\n",
        "\n",
        "\n",
        "                ### control\n",
        "                control_y_interval_hi = np.asarray([hdi_hi_intercept,\n",
        "                                                    hdi_hi_intercept + split_point*hdi_hi_post,\n",
        "                                                    hdi_hi_intercept + hdi_hi_post\n",
        "                                                   ])\n",
        "                control_y_interval_lo = np.asarray([hdi_lo_intercept,\n",
        "                                                    hdi_lo_intercept + split_point*hdi_lo_post,\n",
        "                                                    hdi_lo_intercept + hdi_lo_post\n",
        "                                                   ])\n",
        "                line_control_interval_hi = ax[0].plot(x,\n",
        "                                                   control_y_interval_hi,\n",
        "                                                   color=control_color,\n",
        "                                                   alpha=0.1\n",
        "                                                  )\n",
        "                line_control_interval_lo = ax[0].plot(x,\n",
        "                                                   control_y_interval_lo,\n",
        "                                                   color=control_color,\n",
        "                                                   alpha=0.1\n",
        "                                                  )\n",
        "\n",
        "\n",
        "                ax[0].fill_between(x, np.ravel(control_y_interval_hi),\n",
        "                                np.ravel(control_y_interval_lo),\n",
        "                                color=control_color, alpha=0.1)\n",
        "\n",
        "\n",
        "                y_lo = np.min([control_y_interval_lo,\n",
        "                               treat_y_factual_interval_lo,\n",
        "                               treat_y_counterfactual_interval_lo\n",
        "                              ])*1.1\n",
        "                if y_lo > 0: y_lo=0\n",
        "                ax[0].set_ylim(y_lo,\n",
        "                               np.max([control_y_interval_hi,\n",
        "                                       treat_y_factual_interval_hi,\n",
        "                                       treat_y_counterfactual_interval_hi\n",
        "                                      ]) * 1.1\n",
        "                              )\n",
        "\n",
        "\n",
        "\n",
        "            # label the lines.  In multi mode, only label once (on the first pass)\n",
        "            if i==0:\n",
        "                self.label_line(line_treat_counterfactual,\n",
        "                                'Treat counterfactual',\n",
        "                                x_pos=0.7,\n",
        "                                ax=ax[0],\n",
        "                                split_point=split_point,\n",
        "                                label_fontsize=label_fontsize,\n",
        "                                y_pad=y_pad[1],\n",
        "                                above_line = labels_above_line[1]\n",
        "                               )\n",
        "                self.label_line(line_treat_factual,\n",
        "                                'Treat factual',\n",
        "                                x_pos=0.7,\n",
        "                                ax=ax[0],\n",
        "                                split_point=split_point,\n",
        "                                label_fontsize=label_fontsize,\n",
        "                                y_pad=y_pad[0],\n",
        "                                above_line = labels_above_line[0]\n",
        "                               )\n",
        "                self.label_line(line_control,\n",
        "                                'Control actual',\n",
        "                                x_pos=0,\n",
        "                                ax=ax[0],\n",
        "                                split_point=0,\n",
        "                                label_fontsize=label_fontsize,\n",
        "                                y_pad=y_pad[2],\n",
        "                                above_line = labels_above_line[2]\n",
        "                               )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Right-hand side plot:\n",
        "\n",
        "\n",
        "        did_hdi_lo = np.quantile(temp_interact, interval_point_lo)\n",
        "        did_hdi_hi = np.quantile(temp_interact, interval_point_hi)\n",
        "        did_hdi_median = np.quantile(temp_interact, 0.5)\n",
        "        did_hdi_range = did_hdi_hi - did_hdi_lo\n",
        "\n",
        "\n",
        "        # colors '#FDB515'  ''#C4820E'\n",
        "        g = sns.kdeplot(temp_interact, color='#FDB515', fill='#FDB515', alpha=0.1, ax=ax[1])\n",
        "        g = sns.kdeplot(temp_interact, clip=(did_hdi_lo, did_hdi_hi), color='#C4820E', fill='#C4820E', alpha=0.6, ax=ax[1])\n",
        "        g.set_xlim(did_hdi_lo-0.2*did_hdi_range, did_hdi_hi+0.2*did_hdi_range)\n",
        "        g.xaxis.set_tick_params(labelsize=tick_fontsize)\n",
        "        g.yaxis.set_tick_params(labelsize=tick_fontsize)\n",
        "\n",
        "\n",
        "        if did_hdi_lo < 0 and did_hdi_hi > 0:\n",
        "            g.axvline(0, color='#FFF', alpha=0.8, linestyle='--', linewidth=2)\n",
        "\n",
        "\n",
        "        g.axvline(did_hdi_median, color='#333', linestyle=':')\n",
        "        g.annotate(xy=[did_hdi_median + did_hdi_range*0.02, g.get_ylim()[1]*0.02],\n",
        "                   text=f'median:\\n{np.round(did_hdi_median,3)}',\n",
        "                   color='#333', size=label_fontsize+2)\n",
        "        g.axvline(did_hdi_lo, color='#777', linestyle=':')\n",
        "        g.annotate(xy=[did_hdi_lo + did_hdi_range*0.02, g.get_ylim()[1]*.9],\n",
        "                   text=f'{interval_point_lo*100:.1f}%:\\n{np.round(did_hdi_lo,3)}',\n",
        "                   color='#222', size=label_fontsize+2)\n",
        "        g.axvline(did_hdi_hi, color='#777', linestyle=':')\n",
        "        g.annotate(xy=[did_hdi_hi + did_hdi_range*0.02, g.get_ylim()[1]*.9],\n",
        "                   text=f'{interval_point_hi*100:.1f}%:\\n{np.round(did_hdi_hi,3)}',\n",
        "                   color='#222',size=label_fontsize+2)\n",
        "\n",
        "\n",
        "        caption_zero = 'x=0 shown in white if it exists in the HDI.'\n",
        "        ax[1].text(np.mean(g.get_xlim()), g.get_ylim()[1]*0.98, caption_zero, ha='center', size=8, color='#333')\n",
        "\n",
        "\n",
        "        fig.suptitle('Difference-in-Difference Effects', size=suptitle_fontsize)\n",
        "        ax[0].set_title('Control Group versus Treated Group', size=title_fontsize)\n",
        "        ax[1].set_title(f'DiD Highest-Density Interval ({hdi*100}%)', size=title_fontsize)\n",
        "\n",
        "\n",
        "        plt.tight_layout(pad=figsize[0]/5)\n",
        "        sns.despine()\n",
        "        plt.show();\n",
        "\n",
        "\n",
        "    def match_control_nn(self, match_features = [], neighbors=1, scaling=None):\n",
        "        '''\n",
        "        match_control_nn\n",
        "        -----------------\n",
        "        Matching method for control group selection using nearest neighbors with replacement.\n",
        "        Implemented as a KD Tree, with (min/max) rescaled match_features in treat and control.\n",
        "\n",
        "\n",
        "        Does two things:\n",
        "          1) Creates self.data_matched_control internal dataset (does not destroy supplied control set)\n",
        "          2) Recreates self.data_combined to use the new matched control set\n",
        "\n",
        "\n",
        "        match_features:  List of features/columns to use in matching process.  Must be present in\n",
        "                         both df_treat and df_control.\n",
        "        neighbors:       Number of control group members to find per treat member.\n",
        "        scaling:         Accepts minmax, standard.  Default is no scaling.\n",
        "\n",
        "\n",
        "        TODO:\n",
        "        1. Add propensity score logistic regression for matching.\n",
        "        2. Implement method for describing covariate balance between treat and matched control.\n",
        "        3. Currently this only supports xarray.  Genericize this for numpy arrays and pandas/polars dataframes\n",
        "        '''\n",
        "        _scaling = scaling\n",
        "\n",
        "\n",
        "        if scaling is not None:\n",
        "            _scaling = scaling.lower()\n",
        "            if _scaling not in ['minmax', 'standard']:\n",
        "                raise Exception(f'Scaling parameter, if specified, accepts any of [\"minmax\", \"standard\"]. \"{scaling}\" was provided.')\n",
        "\n",
        "\n",
        "        temp_treat   = self.data_treat[match_features].to_dataframe()\n",
        "        temp_control = self.data_control[match_features].to_dataframe().sample(frac=1)  # random shuffle\n",
        "\n",
        "\n",
        "        if _scaling == 'minmax':\n",
        "            scaler = MinMaxScaler()\n",
        "            scaler.fit(temp_treat[match_features])\n",
        "\n",
        "\n",
        "        if _scaling == 'standard':\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(temp_treat[match_features])\n",
        "\n",
        "\n",
        "        if scaling is None:\n",
        "            scaled_treat = temp_treat[match_features]\n",
        "            scaled_control = temp_control[match_features]\n",
        "        else:\n",
        "            scaled_treat = scaler.transform(temp_treat[match_features])\n",
        "            scaled_control = scaler.transform(temp_control[match_features])\n",
        "\n",
        "\n",
        "        search_set = NearestNeighbors(n_neighbors=neighbors)\n",
        "        search_set.fit(scaled_control)\n",
        "        matched_control_set = search_set.kneighbors(scaled_treat)\n",
        "\n",
        "        self.data_matched_control = self.data_control.to_dataframe().iloc[matched_control_set[1].ravel()].to_xarray()\n",
        "        self.data_combined = pd.concat([self.data_treat.to_dataframe(), self.data_matched_control.to_dataframe()]).to_xarray()\n",
        "        self.data_match_features = match_features\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcf7036b-916e-414d-adbf-f47535bf3309",
      "metadata": {
        "id": "bcf7036b-916e-414d-adbf-f47535bf3309"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4cd5e43-a389-4533-a77d-07c2976c24e1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:17:56.764748Z",
          "start_time": "2023-04-27T19:17:56.751964Z"
        },
        "id": "c4cd5e43-a389-4533-a77d-07c2976c24e1"
      },
      "outputs": [],
      "source": [
        "# test data\n",
        "\n",
        "def make_fake_data(treat_size=100, control_size=100, trend=0,\n",
        "                   intervention_effect=1,\n",
        "                   control_mean=10, control_sd=1,\n",
        "                   treat_mean=12, treat_sd=1,\n",
        "                   noise_sd=1\n",
        "                  ):\n",
        "    '''\n",
        "    make_fake_data\n",
        "    --------------\n",
        "    convenience function for demonstration/testing purposes\n",
        "    '''\n",
        "\n",
        "    noise_size = np.max([treat_size, control_size])\n",
        "\n",
        "    data_treat_pre = np.asarray([np.random.normal(loc=treat_mean, scale=treat_sd, size=treat_size),\n",
        "                                 np.ones(treat_size),   # Group=Treat\n",
        "                                 np.zeros(treat_size),  # Period=Post\n",
        "                                 np.random.binomial(n=1, p=0.4, size=treat_size), # Female\n",
        "                                 np.random.gamma(4, 3, size=treat_size), # Risk Score\n",
        "                                 np.random.poisson(3, size=treat_size),   # N ED Visits\n",
        "                                 np.random.beta(12,8, size=treat_size)    # Compliance Rate\n",
        "                                ]\n",
        "                               )\n",
        "    df_treat_pre = pd.DataFrame(data_treat_pre.T)\n",
        "    df_treat_pre.columns = ['Y', 'TREAT', 'POST', 'Female', 'Risk', 'ED', 'Compliance']\n",
        "\n",
        "    data_control_pre = np.asarray([np.random.normal(loc=control_mean, scale=control_sd, size=control_size),\n",
        "                                   np.zeros(control_size),   # Group=Treat\n",
        "                                   np.zeros(control_size),   # Period=Post\n",
        "                                   np.random.binomial(n=1, p=0.5, size=control_size), # Female\n",
        "                                   np.random.gamma(2, 3, size=control_size), # Risk Score\n",
        "                                   np.random.poisson(1, size=control_size),   # N ED Visits\n",
        "                                   np.random.beta(10,10, size=control_size)    # Compliance Rate\n",
        "                                  ]\n",
        "                                 )\n",
        "    df_control_pre = pd.DataFrame(data_control_pre.T)\n",
        "    df_control_pre.columns = ['Y', 'TREAT', 'POST', 'Female', 'Risk', 'ED', 'Compliance']\n",
        "\n",
        "    noise = np.asarray(np.random.normal(loc=0, scale=noise_sd, size=noise_size))\n",
        "\n",
        "    data_treat_post = np.asarray([data_treat_pre[0] * intervention_effect + noise[:treat_size],\n",
        "                                  np.ones(treat_size),   # Group=Treat\n",
        "                                  np.ones(treat_size),   # Period=Post\n",
        "                                  data_treat_pre[3],    # Female\n",
        "                                  data_treat_pre[4],    # Risk Score\n",
        "                                  np.random.poisson(1, size=treat_size),   # N ED Visits\n",
        "                                  np.random.beta(15,10, size=treat_size)    # Compliance Rate\n",
        "                                 ]\n",
        "                                )\n",
        "    df_treat_post = pd.DataFrame(data_treat_post.T)\n",
        "    df_treat_post.columns = ['Y', 'TREAT', 'POST', 'Female', 'Risk', 'ED', 'Compliance']\n",
        "\n",
        "    data_control_post = np.asarray([data_control_pre[0] * trend + noise[:control_size],\n",
        "                                    np.zeros(control_size),   # Group=Treat\n",
        "                                    np.ones(control_size),    # Period=Post\n",
        "                                    data_control_pre[3],    # Female\n",
        "                                    data_control_pre[4],    # Risk Score\n",
        "                                    np.random.poisson(1, size=control_size),   # N ED Visits\n",
        "                                    np.random.beta(12,15, size=control_size)    # Compliance Rate\n",
        "                                   ]\n",
        "                                  )\n",
        "    df_control_post = pd.DataFrame(data_control_post.T)\n",
        "    df_control_post.columns = ['Y', 'TREAT', 'POST', 'Female', 'Risk', 'ED', 'Compliance']\n",
        "\n",
        "    df = pd.concat([df_treat_pre, df_treat_post, df_control_pre, df_control_post], axis=0)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d30c32d2-3e53-4187-8971-90ecadf17677",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:17:56.985695Z",
          "start_time": "2023-04-27T19:17:56.965725Z"
        },
        "id": "d30c32d2-3e53-4187-8971-90ecadf17677"
      },
      "outputs": [],
      "source": [
        "treat_size=300\n",
        "control_size=400\n",
        "data_trend=0.8\n",
        "intervention_effect=0.95\n",
        "control_mean=5\n",
        "control_sd=5\n",
        "treat_mean=10\n",
        "treat_sd=0.5\n",
        "\n",
        "df = make_fake_data(treat_size, control_size, data_trend, intervention_effect, control_mean, control_sd, treat_mean, treat_sd)\n",
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5131167",
      "metadata": {
        "id": "a5131167"
      },
      "source": [
        "### Run DiD on whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d62aa83",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:12.331859Z",
          "start_time": "2023-04-27T19:17:58.334549Z"
        },
        "id": "4d62aa83"
      },
      "outputs": [],
      "source": [
        "model = BModel(data_treat   = df.loc[df['TREAT']==1],\n",
        "               data_control = df.loc[df['TREAT']==0],\n",
        "               treat_var = 'TREAT'\n",
        "              )\n",
        "model.fit(reg_formula = 'Y ~ TREAT + POST + TREAT * POST')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d4611e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:13.524283Z",
          "start_time": "2023-04-27T19:18:13.448096Z"
        },
        "id": "59d4611e"
      },
      "outputs": [],
      "source": [
        "az.summary(model.fitted_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0587e591",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:16.467896Z",
          "start_time": "2023-04-27T19:18:14.046008Z"
        },
        "id": "0587e591"
      },
      "outputs": [],
      "source": [
        "model.plot_trace()\n",
        "plt.tight_layout()\n",
        "sns.despine();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4506cf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:16.485709Z",
          "start_time": "2023-04-27T19:18:16.471321Z"
        },
        "id": "0e4506cf"
      },
      "outputs": [],
      "source": [
        "model.fitted_model['posterior']['TREAT:POST']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c929cc1e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:18.012757Z",
          "start_time": "2023-04-27T19:18:16.487833Z"
        },
        "id": "c929cc1e"
      },
      "outputs": [],
      "source": [
        "model._plot_hdi_density(interval=0.89)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4b8221-ccf1-4090-bc17-f8e342dc0747",
      "metadata": {
        "id": "ef4b8221-ccf1-4090-bc17-f8e342dc0747"
      },
      "outputs": [],
      "source": [
        "model.plot_trace()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e316730",
      "metadata": {
        "id": "0e316730"
      },
      "source": [
        "#### Plot effects for DiD regression\n",
        "\n",
        "First, plot with split point at midline (along x axis)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fca6097",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:18.774677Z",
          "start_time": "2023-04-27T19:18:18.015894Z"
        },
        "id": "5fca6097"
      },
      "outputs": [],
      "source": [
        "model.plot_effects(model, line_type = 'single', split_point=0.5, figsize=(12,5), hdi=0.95,\n",
        "                   suptitle_fontsize=12, title_fontsize=10, label_fontsize=8, tick_fontsize=10,\n",
        "                   show_did=True, y_label='Inpatient Cost PUPM', y_pad=(0.2, 0.35, 0.2), labels_above_line=(True, False, True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "001fd7d9",
      "metadata": {
        "id": "001fd7d9"
      },
      "source": [
        "Next, plot with no split (more to the point, the split point is at $x=0$).  Also, change the HDI to 89%, and leave out the y_label specification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87006b8f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:18:20.358809Z",
          "start_time": "2023-04-27T19:18:19.586653Z"
        },
        "id": "87006b8f"
      },
      "outputs": [],
      "source": [
        "model.plot_effects(model, line_type = 'single', figsize=(12,5), hdi=0.89,\n",
        "                   suptitle_fontsize=12, title_fontsize=10, label_fontsize=8, tick_fontsize=10,\n",
        "                   show_intervals=False, show_did=True, y_pad=(0.2,0.3,0.2), labels_above_line=(True,False,True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a334064",
      "metadata": {
        "id": "0a334064"
      },
      "source": [
        "### Run DiD on treat and matched control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f9e326",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:19:23.643542Z",
          "start_time": "2023-04-27T19:19:09.457387Z"
        },
        "id": "d4f9e326"
      },
      "outputs": [],
      "source": [
        "model.match_control_nn(match_features=['Female', 'Risk'])\n",
        "\n",
        "model.fit(reg_formula = 'Y ~ TREAT + POST + TREAT * POST')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "990ed8a3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:20:40.099353Z",
          "start_time": "2023-04-27T19:20:39.300945Z"
        },
        "id": "990ed8a3"
      },
      "outputs": [],
      "source": [
        "model.plot_effects(model, line_type = 'single', split_point=0.5, figsize=(12,5), hdi=0.89,\n",
        "                   suptitle_fontsize=12, title_fontsize=10, label_fontsize=8, tick_fontsize=10,\n",
        "                   show_did=True, y_pad=(0.3, 0.3, 0.3), labels_above_line=(False, True, True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f591b975",
      "metadata": {
        "id": "f591b975"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d2d2ee3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:23:50.870202Z",
          "start_time": "2023-04-27T19:23:36.882942Z"
        },
        "id": "7d2d2ee3"
      },
      "outputs": [],
      "source": [
        "model.fit(reg_formula = 'Compliance ~ TREAT + POST + TREAT * POST')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "059baf19",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-27T19:24:49.147986Z",
          "start_time": "2023-04-27T19:24:48.336203Z"
        },
        "id": "059baf19"
      },
      "outputs": [],
      "source": [
        "model.plot_effects(model, line_type = 'single', split_point=0.5, figsize=(12,5), hdi=0.89,\n",
        "                   suptitle_fontsize=12, title_fontsize=10, label_fontsize=8, tick_fontsize=10,\n",
        "                   show_did=True, labels_above_line=(True, False, True))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85e4dea8",
      "metadata": {
        "id": "85e4dea8"
      },
      "source": [
        "#### scratch space\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fc9f02",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-30T17:59:47.952409Z",
          "start_time": "2022-12-30T17:59:47.935344Z"
        },
        "id": "23fc9f02"
      },
      "outputs": [],
      "source": [
        "# Rename \"index\" to \"observation\"\n",
        "idx_treat = pd.Index.rename(model.data_treat.index, name='observation')\n",
        "model.data_treat.index = idx_treat\n",
        "\n",
        "idx_control = pd.Index.rename(model.data_control.index, name='observation')\n",
        "model.data_control.index = idx_control\n",
        "\n",
        "idx_matched_control = pd.Index.rename(model.data_matched_control.index, name='observation')\n",
        "model.data_matched_control.index = idx_matched_control\n",
        "\n",
        "idx_combined = pd.Index.rename(model.data_combined.index, name='observation')\n",
        "model.data_combined.index = idx_combined\n",
        "\n",
        "# Create xarrays\n",
        "arr_treat   = xr.Dataset.from_dataframe(model.data_treat)\n",
        "arr_control = xr.Dataset.from_dataframe(model.data_control)\n",
        "arr_matched_control = xr.Dataset.from_dataframe(model.data_matched_control)\n",
        "arr_combined = xr.Dataset.from_dataframe(model.data_combined)\n",
        "\n",
        "# Set attributes\n",
        "attr_dict = {'bistro_version': __version__,\n",
        "             'Treat group variable':'TREAT',\n",
        "             'Post intervention variable':'POST',\n",
        "             'Outcome variable':'Y'\n",
        "            }\n",
        "arr_list = [arr_treat, arr_control, arr_matched_control, arr_combined]\n",
        "\n",
        "for k,v in attr_dict.items():\n",
        "    for arr in arr_list:\n",
        "        arr.attrs[k] = v\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38bbfee",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-31T00:00:52.486114Z",
          "start_time": "2022-12-31T00:00:52.482211Z"
        },
        "id": "f38bbfee"
      },
      "outputs": [],
      "source": [
        "if isinstance(arr_control, xr.core.dataset.Dataset):\n",
        "    print('yup')\n",
        "else:\n",
        "    print('nope')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "772b94bc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-31T00:52:33.146047Z",
          "start_time": "2022-12-31T00:52:33.140782Z"
        },
        "id": "772b94bc"
      },
      "outputs": [],
      "source": [
        "temp_treat_vars = sorted(list(arr_treat.keys()))\n",
        "temp_treat_vars.remove('TREAT')\n",
        "temp_treat_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17675c77",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-31T00:50:39.960445Z",
          "start_time": "2022-12-31T00:50:39.954515Z"
        },
        "id": "17675c77"
      },
      "outputs": [],
      "source": [
        "list(arr_treat.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "614b87d5",
      "metadata": {
        "id": "614b87d5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b67dda6",
      "metadata": {
        "id": "3b67dda6"
      },
      "outputs": [],
      "source": [
        "model.plot_effects()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c4facf9",
      "metadata": {
        "id": "0c4facf9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6929c287",
      "metadata": {
        "id": "6929c287"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f94818b5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-23T20:23:30.415416Z",
          "start_time": "2022-12-23T20:23:28.966916Z"
        },
        "id": "f94818b5"
      },
      "source": [
        "#### Match summaries\n",
        "\n",
        "TODO: we need to use some metadata for TREAT and POST to get the right data for summarization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b05b2d9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-29T22:35:30.235099Z",
          "start_time": "2022-12-29T22:35:30.235082Z"
        },
        "id": "4b05b2d9"
      },
      "outputs": [],
      "source": [
        "def summarize_match():\n",
        "    tbl_control_pre = model.data_control.loc[model.data_control['POST']==0].groupby('TREAT').mean().T\n",
        "    tbl_control_pre.columns = 'TREAT'\n",
        "\n",
        "tbl_control_pre.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ed08f65",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-30T17:35:58.206472Z",
          "start_time": "2022-12-30T17:35:58.188795Z"
        },
        "id": "6ed08f65"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d03a2b7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-27T21:38:08.955334Z",
          "start_time": "2022-12-27T21:38:08.681599Z"
        },
        "id": "6d03a2b7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "584eaf3f",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-27T21:38:14.289062Z",
          "start_time": "2022-12-27T21:38:14.275027Z"
        },
        "id": "584eaf3f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ae4939b",
      "metadata": {
        "id": "7ae4939b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ce6aa60",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-12-29T22:36:10.777605Z",
          "start_time": "2022-12-29T22:36:10.760738Z"
        },
        "id": "3ce6aa60"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from IPython.display import HTML, IFrame, display\n",
        "display(HTML('<h3>Versions used in this notebook</h3>'))\n",
        "pyver_dict = {}\n",
        "pyver_dict['python'], pyver_dict['GCC'] = sys.version.split('\\n')\n",
        "modules_dict = {m.__name__: m.__version__ for m in globals().values() if getattr(m, '__version__', None)}\n",
        "pyver_dict.update(modules_dict)\n",
        "modules_df = pd.DataFrame(pyver_dict, index=[0]).T\n",
        "modules_df.columns = ['Version']\n",
        "modules_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dae769dc",
      "metadata": {
        "id": "dae769dc"
      },
      "outputs": [],
      "source": [
        "model.data_match_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbb72098-5d90-436e-929f-14cd41634b56",
      "metadata": {
        "id": "dbb72098-5d90-436e-929f-14cd41634b56"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}